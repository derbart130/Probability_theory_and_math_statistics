{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home Work 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 1\n",
    "\n",
    "Дана матрица объект-признак\n",
    "\n",
    "**X** = [[ 1.22401313, 2.30868478, 3.03636353, 2.69287214],  \n",
    "    [-0.18757272, 1.30337355, 5.12093014, 3.46363202],  \n",
    "    [-0.81094525, 1.82463398, 5.79686488, 1.86159445],  \n",
    "    [ 0.75129018, 2.67392052, 3.65529809, 1.66746094],  \n",
    "    [ 0.00972362, 1.97367255, 2.50594319, 1.69755173],  \n",
    "    [-0.62972637, 0.77750764, 2.84124027, 4.54410559],  \n",
    "    [ 2.29536229, 1.81206697, 1.95026215, 1.51874636],  \n",
    "    [ 0.0920418 , 2.26971361, 7.47708735, 2.61081203],  \n",
    "    [ 2.39252799, 3.17563985, 3.61420599, 5.10773362],  \n",
    "    [ 0.54983815, 2.87988651, 1.65752765, 1.59635987]]  \n",
    "\n",
    "и значения целевой переменной\n",
    "\n",
    "y = [ 9.26193358, 9.700363 , 8.67214805, 8.74796974, 6.18689108,\n",
    "7.53312713, 7.57643777, 12.44965478, 14.29010746, 6.68361218]\n",
    "\n",
    "1. Подберите два признака (из четырёх) так, чтобы уровень линейной зависимости целевой переменной от значений этих признаков был максимальным. Другими словами, модель линейной регрессии на этих признаках должна давать наилучший результат.\n",
    "2. Является ли значимым получившееся уравнение регрессии?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Решение:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. \n",
    "Для нахождения коэффициентов линейной регрессии будем использовать метод наименьших квадратов:  $$b = (X^\\top X)^{-1} X^\\top Y.$$  \n",
    "Для оценки качества модели будем использовать коэффициент детерминации:  $$R^2 = 1 - \\dfrac{SS_{res}}{SS_{y}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame([[ 1.22401313, 2.30868478, 3.03636353, 2.69287214],  \n",
    "    [-0.18757272, 1.30337355, 5.12093014, 3.46363202],  \n",
    "    [-0.81094525, 1.82463398, 5.79686488, 1.86159445],  \n",
    "    [ 0.75129018, 2.67392052, 3.65529809, 1.66746094],  \n",
    "    [ 0.00972362, 1.97367255, 2.50594319, 1.69755173],  \n",
    "    [-0.62972637, 0.77750764, 2.84124027, 4.54410559],  \n",
    "    [ 2.29536229, 1.81206697, 1.95026215, 1.51874636],  \n",
    "    [ 0.0920418 , 2.26971361, 7.47708735, 2.61081203],  \n",
    "    [ 2.39252799, 3.17563985, 3.61420599, 5.10773362],  \n",
    "    [ 0.54983815, 2.87988651, 1.65752765, 1.59635987]])\n",
    "Y = np.array([ 9.26193358, 9.700363 , 8.67214805, 8.74796974, 6.18689108,\n",
    "7.53312713, 7.57643777, 12.44965478, 14.29010746, 6.68361218])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 4), (10,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_of_squares(samples):\n",
    "    return ((samples - samples.mean()) ** 2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Номера признаков: (0, 1)\n",
      "Коэффициент детерминации: 0.18113594742585215\n",
      "Номера признаков: (0, 2)\n",
      "Коэффициент детерминации: 0.7634246238793152\n",
      "Номера признаков: (0, 3)\n",
      "Коэффициент детерминации: 0.45329667831440756\n",
      "Номера признаков: (1, 2)\n",
      "Коэффициент детерминации: 0.5479482734039012\n",
      "Номера признаков: (1, 3)\n",
      "Коэффициент детерминации: 0.6062055761129932\n",
      "Номера признаков: (2, 3)\n",
      "Коэффициент детерминации: 0.6224419876505322\n"
     ]
    }
   ],
   "source": [
    "x_1 = 0\n",
    "while x_1 <= 3:\n",
    "    for i in range(1, 4):\n",
    "        x_2 = x_1 + i\n",
    "        if x_2 <= 3:\n",
    "            A = X[[x_1, x_2]].values\n",
    "            ones = np.ones((A.shape[0], 1))\n",
    "            A = np.hstack((ones, A))\n",
    "            XTX = A.T.dot(A)\n",
    "            XTX_inv = np.linalg.inv(XTX)\n",
    "            b = XTX_inv.dot(A.T).dot(Y)\n",
    "            z = A.dot(b)\n",
    "            r = 1 - ((Y - z)**2).sum() / sum_of_squares(Y)\n",
    "            print(f'Номера признаков: {x_1, x_2}\\nКоэффициент детерминации: {r}')\n",
    "        else:\n",
    "            break\n",
    "    x_1 += 1    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом получаем, что наилучший результат даёт модель линейной регрессии с признаками: X[0] и X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.29205855  9.52293042  9.32854895  9.2734825   6.67593463  6.04279092\n",
      "  9.71768655 12.83152181 11.89122916  6.52606129]\n",
      "Коэффициент детерминации: 0.7634246238793152\n"
     ]
    }
   ],
   "source": [
    "A = X[[0, 2]].values\n",
    "ones = np.ones((A.shape[0], 1))\n",
    "A = np.hstack((ones, A))\n",
    "XTX = A.T.dot(A)\n",
    "XTX_inv = np.linalg.inv(XTX)\n",
    "b = XTX_inv.dot(A.T).dot(Y)\n",
    "result = A.dot(b)\n",
    "r = 1 - ((Y - result)**2).sum() / sum_of_squares(Y)\n",
    "print(result)\n",
    "print(f'Коэффициент детерминации: {r}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Коэффициент детерминации, равный  0.7643 , означает, что  76%  дисперсии переменной  Y  учитывается или объясняется моделью. Оставшиеся  24%  обусловлены какими-то ещё факторами, которые при построении модели не учитывались."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим построенное уравнение регрессии с помощью F-критерия Фишера: $$F_{факт} = \\frac{r_{xy}^{2}}{(1 - r_{xy}^{2})} \\cdot \\frac{k_2}{k_1}$$\n",
    "где:\n",
    "$R^2$ – коэффициент детерминации,  \n",
    "    $n$ – число наблюдений,  \n",
    "    $k$ – число факторов,  \n",
    "    $F_{crit}$ – критическое значение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F = 11.29443912292265\n"
     ]
    }
   ],
   "source": [
    "n = result.shape[0]\n",
    "k1 = 2\n",
    "k2 = n - k1 - 1\n",
    "F = (r / (1 - r)) * (k2 / k1)\n",
    "print(f'F = {F}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F_crit = 4.73741412777588\n"
     ]
    }
   ],
   "source": [
    "p = 0.95\n",
    "alpha = 1 - p\n",
    "F_crit = stats.f.ppf(1 - alpha, k1, k2)\n",
    "print(f'F_crit = {F_crit}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имеем $F>F_{crit}$, следовательно уравнение регрессии статистически значимо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 2\n",
    "\n",
    "Даны значения величины заработной платы заемщиков банка (salary) и значения их поведенческого кредитного скоринга (scoring):\n",
    "\n",
    "salary = [35, 45, 190, 200, 40, 70, 54, 150, 120, 110]\n",
    "scoring = [401, 574, 874, 919, 459, 739, 653, 902, 746, 832]\n",
    "\n",
    "Возьмём в качестве признака значение salary, а в качестве целевой переменной - scoring.\n",
    "\n",
    "1. Найдите коэффициенты линейной регрессии с помощью формул для парной регрессии, а затем с помощью метода наименьших квадратов.\n",
    "2. Постройте scatter plot по данным и отметьте на нём прямую линейной регрессии, полученную в п. 1.\n",
    "3. Посчитайте коэффициент детерминации.\n",
    "4. Оцените построенное уравнение регрессии с помощью F-критерия Фишера.\n",
    "5. Посчитать среднюю ошибку аппроксимации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Решение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([35, 45, 190, 200, 40, 70, 54, 150, 120, 110])\n",
    "y = np.array([401, 574, 874, 919, 459, 739, 653, 902, 746, 832])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Найдите коэффициенты линейной регрессии с помощью формул для парной регрессии, а затем с помощью метода наименьших квадратов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***а)*** Найдём коэффициенты линейной регрессии с помощью формул для парной регрессии:\n",
    "$$b_1 = \\frac{\\overline{yx} - \\overline{y} \\cdot {\\overline{x}}}{\\overline{x^2} - (\\overline{x})^2}, \\: b_0 = \\overline{y} - b_1 \\cdot {\\overline{x}}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6205388824027653"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1 = np.cov(x, y, ddof=0)[0, 1] / np.var(x, ddof=0) \n",
    "b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "444.17735732435955"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b0 = y.mean() - b1 * x.mean()\n",
    "b0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, уравнение регрессии имеет вид (коэффициенты округлены до сотых):$$y = 444.18 + 2.62 \\cdot x$$т.е. с увеличением зарплаты на 1 условную единицу кредитный скоринг увеличивается на 2.62 ед"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***b)*** Найдём коэффициенты линейной регрессии с помощью МНК:\n",
    "\n",
    "Для удобства записи введём дополнительный «фактор» x0 = 1. Поиск коэффициентов линейной регрессии сводится к решению системы линейных уравнений:$$y = X \\cdot b$$где b — столбец коэффициентов регрессии, X — матрица объект-признак, y — столбец целевой переменной. Чаще всего такая система не имеет решений, поэтому задача состоит в минимизации расстояния между векторами $X \\cdot b$ и $y$:$$(X \\cdot b - y)^\\top \\cdot (X \\cdot b - y) \\rightarrow \\min_b.$$Для такой задачи возможно записать аналитическое решение:$$b = (X^\\top X)^{-1} X^\\top y.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[401],\n",
       "       [574],\n",
       "       [874],\n",
       "       [919],\n",
       "       [459],\n",
       "       [739],\n",
       "       [653],\n",
       "       [902],\n",
       "       [746],\n",
       "       [832]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = x.reshape(-1, 1)\n",
    "\n",
    "y2 = y.reshape(-1, 1)\n",
    "y2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К матрице 𝑋 (массив x1) нужно также добавить столбец из 1 , соответствующий фиктивному фактору."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = np.ones((x2.shape[0], 1))\n",
    "x2 = np.hstack((ones, x2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишем матрицу 𝑋⊤𝑋 и посчитаем её определитель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "349464.00000000023"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTX = x2.T.dot(x2)\n",
    "\n",
    "np.linalg.det(XTX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определитель не близок к нулю, поэтому можно записать аналитическое решение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[444.17735732]\n",
      " [  2.62053888]]\n"
     ]
    }
   ],
   "source": [
    "XTX_inv = np.linalg.inv(XTX)\n",
    "\n",
    "b = XTX_inv.dot(x2.T).dot(y2)\n",
    "\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Модель линейной регрессии$$y = b_0 + b_1 x_1 + \\dots + b_k x_k$$называется несмещённой, если математические ожидания правой и левой части равны:$$M(y) = M(b_0 + b_1 x_1 + \\dots + b_k x_k)$$Как правило, несмещённые модели имеют лучшую обобщающую способность, чем смещённые, несмотря на то, что смещённые модели могут потенциально давать лучшие значения метрик качества (о них — чуть позже), чем несмещённые.\n",
    "\n",
    "Проверим несмещённость уравнения регрессии из предыдущего примера:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(709.8999999999999, 709.9)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.dot(b).mean(), y2.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Постройте scatter plot по данным и отметьте на нём прямую линейной регрессии, полученную в п. 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ox = x\n",
    "oy = b0 + b1 * ox\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.plot(ox, oy, color='red', alpha=0.5)\n",
    "\n",
    "plt.xlabel('salary')\n",
    "plt.ylabel('scoring');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** Посчитайте коэффициент детерминации \n",
    "\n",
    "Коэффициент детерминации:\n",
    "$$R^2 = 1 - \\dfrac{\\sigma^2_{res}}{\\sigma^2_{y}}$$\n",
    "Для несмещённых моделей регрессии коэффициент детерминации можно также посчитать как квадрат коэффициента корреляции между объясняемой переменной $y$ и предсказанной переменной $z$:$$R^2 = r_{yz}^2.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[401.        , 535.89621821],\n",
       "       [574.        , 562.10160703],\n",
       "       [874.        , 942.07974498],\n",
       "       [919.        , 968.2851338 ],\n",
       "       [459.        , 548.99891262]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = b0 + b1 * x\n",
    "\n",
    "np.vstack([y, z]).T[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7876386635293686"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R1 = 1 - (z - y).var() / y.var()\n",
    "R1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Коэффициент детерминации, равный 0.7876 , означает, что 79% дисперсии переменной 𝑦 учитывается или объясняется моделью. Оставшиеся 21% обусловлены какими-то ещё факторами, которые модель не учла.\n",
    "\n",
    "Поскольку наша модель является несмещённой, то же значение можно посчитать как квадрат коэффициента корреляции между массивами x1 и y1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.78763866],\n",
       "       [0.78763866, 1.        ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(x, y) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** Оцените построенное уравнение регрессии с помощью F-критерия Фишера.\n",
    "\n",
    "Оценить статистическую значимость уравнения линейной регрессии в целом можно с помощью F-критерия Фишера. Проверяется нулевая гипотеза о том, что все коэффициенты при факторах у регрессионной модели равны нулю (т.е. модель представляет из себя горизонтальную плоскость.)\n",
    "\n",
    "Используемая здесь статистика:$$F = \\dfrac{R^2 / k}{(1 - R^2) / (n - k - 1)},$$где $R^2$ — коэффициент детерминации, $n$ — число наблюдений, $k$ — число факторов. В литературе часто используются обозначения $k_1 = k$, $k_2 = n - k - 1$ (иногда вместо $k_1$, $k_2$ пишут также $f_1$, $f_2$).\n",
    "\n",
    "Данную статистику можно понимать как отношение объяснённой дисперсии к необъяснённой.\n",
    "\n",
    "Критическое значение $F_{сrit} = F(k_1, k_2)$ можно найти по таблице (например, по такой) или с помощью функции scipy.stats.f.ppf.\n",
    "\n",
    "Если $F > F_{crit}$, то нулевая гипотеза отвергается и уравнение регрессии признаётся статистически значимым."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.67164085966451"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k1 = 1\n",
    "k2 = x.shape[0] - k1 - 1\n",
    "\n",
    "F1 = (R1 / k1) / ((1 - R1) / k2)\n",
    "F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для уровня значимости $\\alpha = 0.05$ посчитаем по таблице значение $F_{crit} = F(1, 8)$. Оно равно $5.32$. То же самое с помощью scipy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.317655071578714"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "\n",
    "F_crit = stats.f.ppf(1 - alpha, k1, k2)\n",
    "F_crit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имеем $F > F_{crit}$, поэтому уравнение регрессии статистически значимо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.** Посчитать среднюю ошибку аппроксимации.\n",
    "\n",
    "Cредняя ошибка аппроксимации вычисляется по формуле:$$\\overline{A} = \\frac{1}{n} \\displaystyle\\sum_{i=1}^{n} \\Bigl| {{\\frac{y_i - z_i}{y_i}} \\Bigr|}.$$\n",
    "\n",
    "Если $\\overline{A}$ не превышает $8$-$10 \\%$, можно сказать, что теоретические значения близки к тем, которые выдает модель линейной регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_approximation_error(y_real: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    return np.abs((y_real - y_pred) / y_real).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11469251843561708"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_approximation_error(y, z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
